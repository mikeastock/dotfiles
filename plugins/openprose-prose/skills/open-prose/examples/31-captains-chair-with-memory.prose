# Captain's Chair with Memory and Self-Improvement
#
# An advanced orchestration pattern that includes:
# - Retrospective analysis after task completion
# - Learning from mistakes to improve future runs
# - Continuous critic supervision during execution
#
# From the blog post: "Future agents will flip the plan:execute paradigm
# to 80:20 from today's 20:80"

input task: "The task to accomplish"
input past_learnings: "Previous session learnings (if any)"

# ============================================================================
# Agent Definitions
# ============================================================================

agent captain:
  model: opus
  prompt: """You are a senior engineering manager. You coordinate but never code directly.

Your responsibilities:
1. Strategic planning with 80% of effort on planning, 20% on execution oversight
2. Dispatch specialized subagents for all implementation
3. Validate outputs meet requirements
4. Learn from each session to improve future runs

Past learnings to incorporate:
{past_learnings}"""

agent planner:
  model: opus
  prompt: """You are a meticulous planner. Create implementation plans with:
- Exact files and line numbers to modify
- Code patterns to follow from existing codebase
- Edge cases to handle
- Tests to write"""

agent researcher:
  model: haiku
  prompt: "Find specific information quickly. Cite sources."

agent executor:
  model: sonnet
  prompt: "Implement precisely according to plan. Follow existing patterns."

agent critic:
  model: sonnet
  prompt: """You are a continuous critic. Your job is to watch execution and flag:
- Deviations from plan
- Emerging issues
- Opportunities for improvement
Be proactive - don't wait for completion to raise concerns."""

agent retrospective:
  model: opus
  prompt: """You analyze completed sessions to extract learnings:
- What went well?
- What could be improved?
- What should be remembered for next time?
Output actionable insights, not platitudes."""

# ============================================================================
# Phase 1: Deep Planning (80% of effort)
# ============================================================================

# Parallel research - gather everything needed upfront
parallel:
  codebase = session: researcher
    prompt: "Map the relevant parts of the codebase for: {task}"
  patterns = session: researcher
    prompt: "Find coding patterns and conventions used in this repo"
  docs = session: researcher
    prompt: "Find documentation and prior decisions related to: {task}"
  issues = session: researcher
    prompt: "Find known issues, TODOs, and edge cases for: {task}"

# Create detailed implementation plan
let detailed_plan = session: planner
  prompt: """Create a comprehensive implementation plan for: {task}

Use the research to specify:
1. Exact changes needed (file:line format)
2. Code patterns to follow
3. Edge cases from prior issues
4. Test coverage requirements"""
  context: { codebase, patterns, docs, issues }

# Critic reviews plan BEFORE execution
let plan_critique = session: critic
  prompt: "Review this plan for gaps, risks, and unclear requirements"
  context: detailed_plan

# Captain decides if plan needs revision
if **plan critique identified blocking issues**:
  let revised_plan = session: planner
    prompt: "Revise the plan to address critique"
    context: { detailed_plan, plan_critique }
else:
  let revised_plan = detailed_plan

# ============================================================================
# Phase 2: Supervised Execution (20% of effort)
# ============================================================================

# Execute with concurrent critic supervision
parallel:
  implementation = session: executor
    prompt: "Implement according to the plan"
    context: revised_plan
  live_critique = session: critic
    prompt: "Monitor implementation for deviations and emerging issues"
    context: revised_plan

# Captain validates and integrates
let validated = session: captain
  prompt: """Validate the implementation:
- Does it match the plan?
- Were critic's live concerns addressed?
- Is it ready for user review?"""
  context: { implementation, live_critique, revised_plan }

# ============================================================================
# Phase 3: Retrospective and Learning
# ============================================================================

# Extract learnings for future sessions
let session_learnings = session: retrospective
  prompt: """Analyze this completed session:

Plan: {revised_plan}
Implementation: {implementation}
Critique: {live_critique}
Validation: {validated}

Extract:
1. What patterns worked well?
2. What caused friction or rework?
3. What should the captain remember next time?
4. Any codebase insights to preserve?"""
  context: { revised_plan, implementation, live_critique, validated }

# Output both the result and the learnings
output result = validated
output learnings = session_learnings
